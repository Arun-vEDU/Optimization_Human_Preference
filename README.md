## File Structure

Model_DPOTrainer.ipynb -> Selected a publicly available dataset, and implemented the Direct Preference Optimization (DPO) training method with DPOTrainer Function
using a pre-trained transformer model (GPT2). Save the trained model.

Hugging_Face.ipynb -> Loaded the Saved trained model and uploaded the model to the Hugging Face Model Hub.

app.py -> The app allow users to input text and receive response.

## Experiment (hyperparameters and training performance)

|Step	|Training Loss |
|-----|--------------|
|100	|0.694500 |
|200	|0.688000 |
|300	|0.688300 |
|400	|0.696100 |
|500	|0.689300 |


## Link for Hugging Face Hub

https://huggingface.co/arunyasenadeera/A5dpo-finetuned-model

## Web Application Development
[![Watch the video](https://img.youtube.com/vi/8nl4b9R7dkQ/0.jpg)](https://www.youtube.com/watch?v=8nl4b9R7dkQ)
